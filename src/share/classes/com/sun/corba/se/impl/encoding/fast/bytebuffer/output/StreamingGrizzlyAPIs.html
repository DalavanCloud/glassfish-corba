<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
<head>
  <meta content="text/html;charset=ISO-8859-1" http-equiv="Content-Type">
  <title>StreamingGrizzlyAPIs</title>
</head>
<body>
<h1>Streaming APIs for Grizzly</h1>
One important aspect of Java network communications is proper buffer
management. This becomes a big issue because of the java.nio.ByteBuffer
class that must be used in the java.nio classes.&nbsp; In particular,
java support direct ByteBuffers which are not heap allocated.&nbsp;
Direct ByteBuffers are expensive to create, and slow to be recovered by
the garbage collector.&nbsp; This leads to two problems if a naive
implementation is used:<br>
<ol>
  <li>IO may be slower than desired because of frequent direct
ByteBuffer allocations.</li>
  <li>Since a system may need large amounts of memory for message
buffering, the slow reclamation of direct ByteBuffers can result in
OutOfMemory errors.</li>
</ol>
One way of attacking this problem is to remove the disadvantages of
heap ByteBuffers, so that direct ByteBuffers are not needed for IO.
Charlie Hunt is pursuing this, but it requires significant work in the
Java VM compilers and garbage collectors, so it is unlikely to show up
very soon
in Java (certainly not before JDK 7 is released). Consequently, we need
to look at a different solution.<br>
<br>
To avoid frequent allocations, we want to infrequently allocate large
ByteBuffers (which I'll call Slabs here) and then carve the Slab into
smaller pieces for individual IO operations. The Slabs
can be pooled, so that empty Slabs can be re-used. In order to do this,
we need to properly dispose of the individual allocations from the
Slab.&nbsp;
This essentially means we are need some kind of manual memory
management in Java (unfortunately). To make this palatable, we bury the
use of buffers behind a streaming API, so that the client need
not ever interact directly with ByteBuffers (except possibly in
simple ways in setting up a ProtocolChain for Grizzly).<br>
<br>
This document describes the APIs and their implementation in detail,
together with some notes on possible integration with Grizzly and use
of these APIs in CORBA. The implementation is currently complete, but
not fully tested.<span style="font-weight: bold;"><br>
</span>
<h2><span style="font-weight: bold;">Buffer Management</span></h2>
There are several fundamental APIs in this design that are used for
buffer management:<br>
<ul>
  <li><a href="Allocator.html">Allocator</a> provides two allocate
methods:
one that allocates a buffer of a given size, the other allows a minimum
and maximum size. The second form is intended for use in a channel
reader, which may (for example) prefer a buffer of 100K, but requires
at least 10K for reasonable efficiency. There are two implementations
of an allocator: a pooled implementation and a non-pooled
implementation.&nbsp; Either implementation may be used with direct or
heap ByteBuffers.<br>
  </li>
  <li><a href="BufferWrapper.html">BufferWrapper</a> is a wrapper
around a
ByteBuffer, and is the result of an Allocator.allocate call.
BufferWrappers provide a number of convenience methods, some of which
hide ByteBuffer manipulations.&nbsp; Each BufferWrapper has a small
amount of space reserved before the start of the data for an efficient
prepend operation.&nbsp; For example, reading of split primitives is
handled in the streams by using an 8-byte header, so that 5 bytes from
the start of a long can be easily prepended to the remaining 3 bytes in
the next buffer. prepend may also be useful for things like handling
the 12 byte GIOP header in CORBA. Note that the dispose method on the
BufferWrapper must be called once the stream is finished with the
BufferWrapper.<br>
  </li>
  <li><a href="AllocatorFactory.html">AllocatorFactory</a> is used to
create both kinds of Allocators, and also to create SlabPools.<br>
  </li>
  <li><a href="AllocatorFactory.html">AllocatorFactory.SlabPool</a> is
used
to hold a number of Slabs.&nbsp; A SlabPool can be shared by a number
of pool Allocators, but note that each Allocator always has one Slab
associated with it, so it may be necessary to control the number of
pool Allocators.</li>
</ul>
&nbsp;
Here is a UML class diagram that illustrates these APIs and their
implementation:<br>
<br>
<img style="width: 1054px; height: 904px;" alt="Allocator class diagram"
 src="AllocatorClasses.crop.png"><br>
<h2><br>
<span style="font-weight: bold;"></span></h2>
For convenience, here are links to all of the allocator related classes:<br>
<ul>
  <li><a href="Allocator.html">Allocator</a>, the basic interface.</li>
  <ul>
    <li><a href="AllocatorBase.html">AllocatorBase</a>, the abstract
base class for Allocator implementations.</li>
  </ul>
  <ul>
    <ul>
      <li><a href="AllocatorImpl.html">AllocatorImpl</a>, the simple
(non-pooled) allocator.</li>
    </ul>
  </ul>
  <ul>
    <ul>
      <li><a href="AllocatorPoolImpl.html">AllocatorPoolImpl</a>, the
pooled allocator.</li>
    </ul>
  </ul>
  <li><a href="AllocatorFactory.html">AllocatorFactory</a>. the static
library class used to create Allocators and SlabPools.<br>
  </li>
  <li><a href="BufferWrapper.html">BufferWrapper</a>, the wrapper
around ByteBuffer which Allocators return.<br>
  </li>
  <li><a href="SlabPoolImpl.html">SlabPoolImpl</a>, the implementation
of the AllocatorFactory.SlabPool interface.<br>
  </li>
  <li><a href="Slab.html">Slab</a>, the representation of large
ByteBuffers used for allocation.<br>
  </li>
</ul>
<a href="AllocatorBase.html">AllocatorBase</a> maintains a reference to
the current slab, which is used for allocations.&nbsp; The details of
obtaining and releasing a slab, and of disposing a <a
 href="BufferWrapper.html">BufferWrapper</a> allocated from a slab, are
captured in the abstract methods. The <a href="AllocatorFactory.html">AllocatorFactory</a>
interface provides a means to create Allocator and SlabPool instances.<br>
<br>
The <a href="SlabPoolImpl.html">SlabPool</a> internally maintains
queues of Slabs in 3 possible states:<br>
<ul>
  <li>Empty, which means that capacity=limit and position=0, and all
allocated space has been disposed. Calls to
AllocatorPoolImpl.obtainSlab are satisfied either by getting an empty
Slab, or by creating a new Slab if none exists.<br>
  </li>
  <li>Partial, which means that position is &gt;= 0, and possibly part
of the allocated data has been disposed.<br>
  </li>
  <li>Full, which means that position == limit, and part but not all of
the allocated data has been disposed. A count is maintained of the
total disposed size.&nbsp; When this is equal to the allocated size,
the Full Slab state is changed to Empty and the Slab is moved to the
empty queue.<br>
  </li>
</ul>
<a href="AllocatorFactory.html">AllocatorFactory</a>.makePoolAllocator
allows a number of pool allocators to be created from the same shared <a
 href="SlabPoolImpl.html">SlabPool</a>. Each such <a
 href="Allocator.html">Allocator</a> will get its own Slab for its
exclusive use. This should minimize contention in highly concurrent
systems.<br>
<h2>Streams for Reading and Writing</h2>
Streams provide a useful IO abstraction, because they hide the buffer
management complexities from the user.&nbsp; Like ByteBuffer, streams
also support both big and little endian data representation. I have
defined 3 interfaces and classes in this area;<br>
<ul>
  <li><a href="Reader.html">Reader,</a> which provides support for
getting Java primitives and arrays of primitives from a sequence of
buffers. Primitive arrays are provided because they can be implemented
much more efficiently than simply getting each element individually.
Reader provides 3 other important methods for general use:</li>
  <ul>
    <li>void receiveData( BufferWrapper ), which is used to add more
data to the Reader</li>
    <li>int availableDataSize(), which returns the amount of data
available for get calls in the Reader</li>
    <li>void getBytes( BufferWrapper ), which can be used to fill a
BufferWrapper from one data source, then the result can be added to
another Reader's receiveData method. For example, when a GIOP
ProtocolParser parses a message, it can use getBytes to do so, and
enqueue message fragments directly onto a CDRInputStream.</li>
  </ul>
  <li><a href="Writer.html">Writer</a>, which provides support for
putting Java primitives and arrays of primitive into a sequence of
buffers. Each Writer instance has an associated Writer.BufferHandler,
which defines two methods:</li>
  <ul>
    <li>BufferWrapper overflow( BufferWrapper ), which is called
whenever the Writer's current BufferWrapper is too full for the next
primitive type to be written (arrays are automatically split across
multiple buffers. QUESTION: do we need a bit more support for available
size here to deal with GIOP's twisted fragmentation requirements?). A
typical implementation of the overflow method does something like the
following:</li>
    <ul>
      <li>If the argument is not null, it is written to a
channel.&nbsp; After successful completion of the write (if we are
using non-blocking writes), this old buffer can be disposed of.</li>
      <li>A new BufferWrapper is allocated from the current allocator
(often a pool Allocator assigned to the current thread).</li>
      <li>This new BufferWrapper is returned.</li>
    </ul>
    <li>close( BufferWrapper ).&nbsp; Here the intent is simply to
write and dispose of the buffer, but NOT to allocate a new buffer.</li>
  </ul>
  <li><a href="StreamFactory.html">StreamFactory</a>, which provides
simple methods for creating Reader and Writer instances.<br>
  </li>
</ul>
Here is a UML class diagram of the Stream classes:<br>
<br>
<img style="width: 1054px; height: 1210px;" alt="Stream class diagram"
 src="StreamClasses.crop.png"><br>
<br>
Here is a summary of the stream related classes:<br>
<ul>
  <li><a href="Reader.html">Reader</a>, the Reader interface</li>
  <ul>
    <li><a href="ReaderImpl.html">ReaderImpl</a>, the implementation of
the Reader interface</li>
  </ul>
  <li><a href="Writer.html">Writer</a>, the write stream interface</li>
  <ul>
    <li><a href="WriterImpl.html">WriterImpl</a>, the implementation of
the Writer interface</li>
  </ul>
  <li><a href="StreamFactory.html">StreamFactory</a>, which provides
static factory methods for Reader and Writer<br>
  </li>
</ul>
<br>
<h2>Using the allocators and streams</h2>
The basic model should work as follows:<br>
<ol>
  <li>A read event is generated by a Selector. This is dispatched to
the ProtocolChain, where the ReadFilter does something like:</li>
  <ol>
    <li>Assign a thread (if necessary) to do the IO for the available
data (and deal with SelectionKey as usual).</li>
    <li>Allocated a buffer from the current thread's Allocator using
allocate( minSizeToRead, maxSizeToAllocate ). For example,
minSizeToRead might be set to 4K to avoid small reads that would
quickly result in another read event, and maxSizeToRead might be set to
64K, to avoid wasting too much space (the slab must be somewhat larger
than the maximum size) in all of the threads that have attached
allocators.</li>
    <li>Read the data from the channel into the buffer.</li>
    <li>Get/create the Reader for this channel.&nbsp; Attach it to some
context to make it available to the protocol parser</li>
    <li>Invoke the protocol parser with the Reader (or a context from
which the Reader may be obtained).</li>
  </ol>
  <li>Control passes to the ProtocolParser.&nbsp; In the GIOP case,
this looks something like:</li>
</ol>
&nbsp;&nbsp;&nbsp; boolean invokeParser( Reader reader ) {<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; boolean stop = false ;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; while (!stop) {<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
switch (state) {<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
case HEADER:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
if (reader.availableDataSize() &gt;= GIOP_HEADER_SIZE) {<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
reader.getBytes( header ) ;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
state = BODY ;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
// parse header and use that to set expectedBodySize<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
} else {<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
stop = true ;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
}<br>
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
case BODY:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
if (reader.availableDataSize() &gt;= expectedBodySize) {<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
BufferWrapper body = allocator.allocate( expectedBodySize ) ;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
reader.getBytes( body ) ;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
state = HEADER ;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
body.prepend( header ) ;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
// create message mediator for further processing of data<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
} else {<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
stop = true ;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
}<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }<br>
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; // return moreWorkToDo based
on outstanding requests<br>
&nbsp;&nbsp;&nbsp; }<br>
<br>
Note that the Protocol parser has state:<br>
<ul>
  <li>The state variable, which always has either HEADER or BODY as its
value</li>
  <li>expectedBodySize</li>
  <li>An ORB, to access the CorbaMessageMediator and related machinery</li>
  <li>An allocator, which may simply be a ThreadLocal</li>
</ul>
The switch statement is used to allow us to correctly resume execution
from where we left off on the last call when there was not enough data
available to read the next header or body.<br>
<br>
One other thing I'd like to look at here: can we get to only one place
in the ORB that maps from Connections to fragmented requests?<br>
SocketOrChannelConnectionImpl already maintains a map from request ID
to message mediator.&nbsp; Basically, if this map is NOT empty, we
expect to read more data.&nbsp; So do we really need to maintain all of
this information in the protocol parser?<br>
</body>
</html>
